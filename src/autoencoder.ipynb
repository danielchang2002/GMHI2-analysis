{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bf2f3d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import get_species, get_labels, get_labels_all\n",
    "from utils import get_taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6da7597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_all = get_taxonomy(), get_labels(), get_labels_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3aae568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = (\n",
    "    (y_all == \"Underweight\").values.flatten() | \n",
    "    (y_all == \"Overweight\").values.flatten() |\n",
    "    (y_all == \"Obesity\").values.flatten() |\n",
    "    (y_all == \"Obese\").values.flatten() |\n",
    "    (X['UNKNOWN'] >= 100).values.flatten()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e36e1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_all = X.iloc[~remove, :], y.iloc[~remove, :], y_all.iloc[~remove, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c1a384ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10004, 3200)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac0d8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "studies = np.unique(X.index.get_level_values(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "20d7c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "perm = np.random.permutation(len(studies))\n",
    "prop = 0.90\n",
    "train_idx, test_idx = perm[:int(len(studies) * prop)], perm[int(len(studies) * prop):]\n",
    "train_studies = studies[train_idx]\n",
    "test_studies = studies[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a8c9e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.00001\n",
    "X_train, y_train = X.loc[train_studies], y.loc[train_studies]\n",
    "X_test, y_test = X.loc[test_studies], y.loc[test_studies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b54f3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoder_hidden_layer = nn.Linear(\n",
    "            in_features=kwargs[\"input_shape\"], out_features=128\n",
    "        ).float()\n",
    "        self.encoder_output_layer = nn.Linear(\n",
    "            in_features=128, out_features=128\n",
    "        ).float()\n",
    "        self.decoder_hidden_layer = nn.Linear(\n",
    "            in_features=128, out_features=128\n",
    "        ).float()\n",
    "        self.decoder_output_layer = nn.Linear(\n",
    "            in_features=128, out_features=kwargs[\"input_shape\"]\n",
    "        ).float()\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_hidden_layer(features)\n",
    "        activation = torch.relu(activation)\n",
    "        code = self.encoder_output_layer(activation)\n",
    "        code = torch.relu(code)\n",
    "        activation = self.decoder_hidden_layer(code)\n",
    "        activation = torch.relu(activation)\n",
    "        activation = self.decoder_output_layer(activation)\n",
    "        reconstructed = torch.relu(activation)\n",
    "        \n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3e46e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = AE(input_shape=3200).to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7076a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 1.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor = torch.as_tensor(1.0 * (X > c).values, device=device).float()\n",
    "X_train_tensor = torch.as_tensor(1.0 * (X_train > c).values, device=device).float()\n",
    "X_test_tensor = torch.as_tensor(1.0 * (X_test > c).values, device=device).float()\n",
    "X_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "22ac332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_loader = torch.utils.data.DataLoader(\n",
    "    X_tensor, batch_size=128, shuffle=True, pin_memory=True\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    X_train_tensor, batch_size=128, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    X_test_tensor, batch_size=32, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3e2ea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/100, loss = 0.042360\n",
      "epoch : 2/100, loss = 0.028050\n",
      "epoch : 3/100, loss = 0.023879\n",
      "epoch : 4/100, loss = 0.022232\n",
      "epoch : 5/100, loss = 0.021266\n",
      "epoch : 6/100, loss = 0.020514\n",
      "epoch : 7/100, loss = 0.019961\n",
      "epoch : 8/100, loss = 0.019409\n",
      "epoch : 9/100, loss = 0.019030\n",
      "epoch : 10/100, loss = 0.018730\n",
      "epoch : 11/100, loss = 0.018458\n",
      "epoch : 12/100, loss = 0.018197\n",
      "epoch : 13/100, loss = 0.017978\n",
      "epoch : 14/100, loss = 0.017762\n",
      "epoch : 15/100, loss = 0.017559\n",
      "epoch : 16/100, loss = 0.017426\n",
      "epoch : 17/100, loss = 0.017269\n",
      "epoch : 18/100, loss = 0.017135\n",
      "epoch : 19/100, loss = 0.017031\n",
      "epoch : 20/100, loss = 0.016903\n",
      "epoch : 21/100, loss = 0.016819\n",
      "epoch : 22/100, loss = 0.016682\n",
      "epoch : 23/100, loss = 0.016609\n",
      "epoch : 24/100, loss = 0.016526\n",
      "epoch : 25/100, loss = 0.016462\n",
      "epoch : 26/100, loss = 0.016403\n",
      "epoch : 27/100, loss = 0.016309\n",
      "epoch : 28/100, loss = 0.016240\n",
      "epoch : 29/100, loss = 0.016220\n",
      "epoch : 30/100, loss = 0.016152\n",
      "epoch : 31/100, loss = 0.016097\n",
      "epoch : 32/100, loss = 0.016080\n",
      "epoch : 33/100, loss = 0.015980\n",
      "epoch : 34/100, loss = 0.015966\n",
      "epoch : 35/100, loss = 0.015892\n",
      "epoch : 36/100, loss = 0.015840\n",
      "epoch : 37/100, loss = 0.015797\n",
      "epoch : 38/100, loss = 0.015771\n",
      "epoch : 39/100, loss = 0.015727\n",
      "epoch : 40/100, loss = 0.015708\n",
      "epoch : 41/100, loss = 0.015681\n",
      "epoch : 42/100, loss = 0.015646\n",
      "epoch : 43/100, loss = 0.015604\n",
      "epoch : 44/100, loss = 0.015560\n",
      "epoch : 45/100, loss = 0.015546\n",
      "epoch : 46/100, loss = 0.015508\n",
      "epoch : 47/100, loss = 0.015473\n",
      "epoch : 48/100, loss = 0.015444\n",
      "epoch : 49/100, loss = 0.015478\n",
      "epoch : 50/100, loss = 0.015451\n",
      "epoch : 51/100, loss = 0.015359\n",
      "epoch : 52/100, loss = 0.015338\n",
      "epoch : 53/100, loss = 0.015329\n",
      "epoch : 54/100, loss = 0.015314\n",
      "epoch : 55/100, loss = 0.015341\n",
      "epoch : 56/100, loss = 0.015302\n",
      "epoch : 57/100, loss = 0.015281\n",
      "epoch : 58/100, loss = 0.015219\n",
      "epoch : 59/100, loss = 0.015182\n",
      "epoch : 60/100, loss = 0.015170\n",
      "epoch : 61/100, loss = 0.015157\n",
      "epoch : 62/100, loss = 0.015158\n",
      "epoch : 63/100, loss = 0.015110\n",
      "epoch : 64/100, loss = 0.015096\n",
      "epoch : 65/100, loss = 0.015115\n",
      "epoch : 66/100, loss = 0.015068\n",
      "epoch : 67/100, loss = 0.015061\n",
      "epoch : 68/100, loss = 0.015027\n",
      "epoch : 69/100, loss = 0.015042\n",
      "epoch : 70/100, loss = 0.015015\n",
      "epoch : 71/100, loss = 0.014968\n",
      "epoch : 72/100, loss = 0.015010\n",
      "epoch : 73/100, loss = 0.014959\n",
      "epoch : 74/100, loss = 0.014947\n",
      "epoch : 75/100, loss = 0.014931\n",
      "epoch : 76/100, loss = 0.014956\n",
      "epoch : 77/100, loss = 0.014981\n",
      "epoch : 78/100, loss = 0.014933\n",
      "epoch : 79/100, loss = 0.014921\n",
      "epoch : 80/100, loss = 0.014878\n",
      "epoch : 81/100, loss = 0.014871\n",
      "epoch : 82/100, loss = 0.014845\n",
      "epoch : 83/100, loss = 0.014853\n",
      "epoch : 84/100, loss = 0.014835\n",
      "epoch : 85/100, loss = 0.014852\n",
      "epoch : 86/100, loss = 0.014842\n",
      "epoch : 87/100, loss = 0.014808\n",
      "epoch : 88/100, loss = 0.014842\n",
      "epoch : 89/100, loss = 0.014729\n",
      "epoch : 90/100, loss = 0.014542\n",
      "epoch : 91/100, loss = 0.014549\n",
      "epoch : 92/100, loss = 0.014511\n",
      "epoch : 93/100, loss = 0.014520\n",
      "epoch : 94/100, loss = 0.014483\n",
      "epoch : 95/100, loss = 0.014507\n",
      "epoch : 96/100, loss = 0.014509\n",
      "epoch : 97/100, loss = 0.014478\n",
      "epoch : 98/100, loss = 0.014473\n",
      "epoch : 99/100, loss = 0.014476\n",
      "epoch : 100/100, loss = 0.014457\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for batch_features in X_loader:\n",
    "        # load it to the active device\n",
    "        batch_features = batch_features.view(-1, 3200).to(device)\n",
    "        \n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute reconstructions\n",
    "        outputs = model(batch_features)\n",
    "        \n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, batch_features)\n",
    "        \n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d34d1648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.5800, 1.6527,  ..., 0.0000, 1.2841, 0.0000],\n",
       "        [0.0000, 2.0115, 1.3123,  ..., 0.0000, 2.3784, 0.0000],\n",
       "        [0.0000, 1.8580, 1.3846,  ..., 0.0000, 2.8246, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 2.6081, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 3.0618, 1.1666,  ..., 0.0000, 1.2878, 0.0000],\n",
       "        [0.0000, 1.5808, 1.6466,  ..., 0.0000, 1.8156, 0.0000]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = X_tensor\n",
    "activation = model.encoder_hidden_layer(features)\n",
    "activation = torch.relu(activation)\n",
    "code = model.encoder_output_layer(activation)\n",
    "code = torch.relu(code)\n",
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "10ef4ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10004, 128])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f6dcfd51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.,  9.,  9., ..., 35., 35., 35.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "sample_studies = np.array(X.index.get_level_values(0))\n",
    "o = OrdinalEncoder()\n",
    "groups = o.fit_transform(sample_studies.reshape((len(sample_studies), 1))).flatten()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c69206b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "logo = LeaveOneGroupOut()\n",
    "kfold = StratifiedKFold(10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ac0000af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done  68 out of  68 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "c = 0.00001\n",
    "clf = LogisticRegression(random_state=42, penalty=\"l1\", solver=\"liblinear\", C=0.3, class_weight=\"balanced\")\n",
    "\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()), ('clf', clf)])\n",
    "\n",
    "predictions = cross_val_predict(pipe, code.detach().numpy(), y.values.flatten(), \n",
    "                         groups=groups, \n",
    "                                cv=logo, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "13c6c488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6867823060214364, 0.6858256697321071)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y, predictions), accuracy_score(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc9ae2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
