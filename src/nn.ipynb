{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466a318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import get_species, get_labels, get_labels_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "571fe73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_all = get_species(), 1.0 * get_labels(), get_labels_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d5db434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ..., False, False,  True])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ((X > 0.00001).mean(axis=0) > 0.01).values\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a558cd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12532, 542)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.iloc[:, cols]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8577d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12532, 413)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X[list(filter(lambda x : \"virus\" not in x and \"Virus\" not in x and \"unclassified\" not in x, X.columns))]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7996681",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ((y_all == \"Underweight\") | (y_all == \"Overweight\") | (y_all == \"Obesity\")).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a210bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, y_all = X.iloc[~remove, :], y.iloc[~remove, :], y_all.iloc[~remove, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3277a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PHENOTYPE_Disease</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Study_ID</th>\n",
       "      <th>Sample Accession</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">GMHI-23</th>\n",
       "      <th>SAMEA3879547</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA3879551</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA3879543</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA3879565</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMEA3879546</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">P140</th>\n",
       "      <th>SAMN07509557</th>\n",
       "      <td>Ulcerative colitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMN07509558</th>\n",
       "      <td>Ulcerative colitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMN07509546</th>\n",
       "      <td>Ulcerative colitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMN07509552</th>\n",
       "      <td>Ulcerative colitis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAMN07509921</th>\n",
       "      <td>Ulcerative colitis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10039 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            PHENOTYPE_Disease\n",
       "Study_ID Sample Accession                    \n",
       "GMHI-23  SAMEA3879547                 Healthy\n",
       "         SAMEA3879551                 Healthy\n",
       "         SAMEA3879543                 Healthy\n",
       "         SAMEA3879565                 Healthy\n",
       "         SAMEA3879546                 Healthy\n",
       "...                                       ...\n",
       "P140     SAMN07509557      Ulcerative colitis\n",
       "         SAMN07509558      Ulcerative colitis\n",
       "         SAMN07509546      Ulcerative colitis\n",
       "         SAMN07509552      Ulcerative colitis\n",
       "         SAMN07509921      Ulcerative colitis\n",
       "\n",
       "[10039 rows x 1 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed94a561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GMHI-10', 'GMHI-11', 'GMHI-13', 'GMHI-14', 'GMHI-15', 'GMHI-17',\n",
       "       'GMHI-19', 'GMHI-2', 'GMHI-21', 'GMHI-23', 'GMHI-24', 'GMHI-26',\n",
       "       'GMHI-27', 'GMHI-28', 'GMHI-3', 'GMHI-31', 'GMHI-32', 'GMHI-33',\n",
       "       'GMHI-4', 'GMHI-5', 'GMHI-9', 'GMHI-V-35', 'GMHI-V-36',\n",
       "       'GMHI-V-38', 'GMHI-V-40', 'GMHI-V-41', 'P103', 'P11', 'P110',\n",
       "       'P113', 'P121', 'P13', 'P132', 'P135', 'P136', 'P140', 'P15',\n",
       "       'P17', 'P2', 'P21', 'P24', 'P32', 'P34', 'P39', 'P4', 'P47', 'P48',\n",
       "       'P53', 'P56', 'P57', 'P59', 'P63', 'P69', 'P74', 'P76', 'P77',\n",
       "       'P8', 'P80', 'P81', 'P86', 'P87', 'P88', 'P89', 'P9', 'P94', 'P95',\n",
       "       'P96', 'P98'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studies = np.unique(X.index.get_level_values(0))\n",
    "studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0955b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "perm = np.random.permutation(len(studies))\n",
    "prop = 0.9\n",
    "train_idx, test_idx = perm[:int(len(studies) * prop)], perm[int(len(studies) * prop):]\n",
    "train_studies = studies[train_idx]\n",
    "test_studies = studies[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "272992bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0.00001\n",
    "X_train, y_train = (X.loc[train_studies].values > c) * 1.0, y.loc[train_studies].values * 1.0\n",
    "X_test, y_test = (X.loc[test_studies].values > c) * 1.0, y.loc[test_studies].values * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1a7e50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9011, 413), (1028, 413), (9011, 1))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7fa6b78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6509337732247948"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "clf = LogisticRegression(random_state=42, penalty=\"l1\", solver=\"liblinear\", C=1, class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train[:, 0])\n",
    "y_hat = clf.predict(X_test)\n",
    "balanced_accuracy_score(y_test[:, 0], y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "021c2fc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w8/85y9rkfs49x53d7kk_ql70bc0000gn/T/ipykernel_7978/1741726969.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7e6c1cbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w8/85y9rkfs49x53d7kk_ql70bc0000gn/T/ipykernel_7978/799634413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "73196aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
    "X_test_t = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
    "y_train_t = torch.from_numpy(y_train).type(torch.FloatTensor)\n",
    "y_test_t = torch.from_numpy(y_test).type(torch.FloatTensor)\n",
    "y_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "02d2d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(413, 30),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(30, 1),\n",
    "    torch.nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "66bae6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "5fa15698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2290.1171875\n",
      "0.4704166622214331\n",
      "0.5107226520207091\n",
      "100 1246.9920654296875\n",
      "0.7840559323934309\n",
      "0.6483843401408418\n",
      "200 1138.917236328125\n",
      "0.8093310101144151\n",
      "0.6549075391180654\n",
      "300 1023.1218872070312\n",
      "0.8369544948222478\n",
      "0.6593700944901748\n",
      "400 859.9425048828125\n",
      "0.8785113084218994\n",
      "0.6571562308098615\n",
      "500 682.5897216796875\n",
      "0.9179660222646457\n",
      "0.6473539290402878\n",
      "600 525.6119995117188\n",
      "0.9460472818757484\n",
      "0.6352580602474954\n",
      "700 399.13861083984375\n",
      "0.9660768301761189\n",
      "0.6183035054922332\n",
      "800 301.90313720703125\n",
      "0.9790474616760219\n",
      "0.6183035054922332\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w8/85y9rkfs49x53d7kk_ql70bc0000gn/T/ipykernel_23527/2511802876.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Backward pass: compute gradient of the loss with respect to model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Calling the step function on an Optimizer makes an update to its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "for t in range(2000):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(X_train_t)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y_train_t)\n",
    "    if t % 100 == 0:\n",
    "        print(t, loss.item())\n",
    "        pred = (model(X_train_t))[:, 0] > 0.5\n",
    "        print(balanced_accuracy_score(pred, y_train_t[:, 0]))\n",
    "        pred = (model(X_test_t))[:, 0] > 0.5\n",
    "        print(balanced_accuracy_score(pred, y_test_t[:, 0]))\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524208b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
